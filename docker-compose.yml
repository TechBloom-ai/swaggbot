version: '3.8'

services:
  # Web UI Service
  swaggbot-web:
    image: swaggbot-web:latest
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - '3003:3000'
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=file:/app/data/swaggbot.db
      - LLM_PROVIDER=${LLM_PROVIDER:-moonshot}
      - MOONSHOT_API_KEY=${MOONSHOT_API_KEY}
      - MOONSHOT_MODEL=${MOONSHOT_MODEL:-kimi-k2.5}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
      - NEXT_PUBLIC_APP_URL=${NEXT_PUBLIC_APP_URL:-http://localhost:3000}
      - RUNNING_IN_DOCKER=true
    volumes:
      - swaggbot-data:/app/data
    restart: unless-stopped
    healthcheck:
      test:
        ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:3000/api/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # MCP Server Service (for opencode integration)
  # This service is designed to be run on-demand via docker-compose run
  swaggbot-mcp:
    image: swaggbot-mcp:latest
    build:
      context: .
      dockerfile: Dockerfile.mcp
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=file:/app/data/swaggbot.db
      - LLM_PROVIDER=${LLM_PROVIDER:-moonshot}
      - MOONSHOT_API_KEY=${MOONSHOT_API_KEY}
      - MOONSHOT_MODEL=${MOONSHOT_MODEL:-kimi-k2.5}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
      - RUNNING_IN_DOCKER=true
    volumes:
      - swaggbot-data:/app/data
    # Stdio transport requires these flags
    stdin_open: true
    tty: true
    # Don't auto-start - only run on demand
    profiles:
      - mcp

volumes:
  swaggbot-data:
    driver: local
